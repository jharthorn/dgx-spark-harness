# v3.3 Sweep Checklist

| Hypothesis | Stack | Profile | Run ID / Pattern | Harness OK? | Signal OK? | Runtime OK? | Notes / Next Actions |
|-----------|-------|---------|------------------|-------------|------------|-------------|----------------------|
| H0        | A     | Comfy   |20251202_012936-20251202_015538|yes|yes|yes|Knee emerges around U64 (latency doubles vs U32)|
| H0        | B     | Comfy   |20251202_072418-20251202_075010|yes|yes|yes|Knee around U64 similar to Stack A but with a heavier p95/p99 spike at U96|
| H2A       | A     | Comfy   |20251202_163703-20251202_164310|yes|yes|yes|Latency scales cleanly with context; no UMA-tier issues; good control baseline for H2B comparison|
| H2B       | B     | Spill   |20251202_165744-20251202_171054|yes|yes|yes|GDS `createXferReq` warnings during KV transfers; consider rerun with tuned cache/transport if needed.|
| H4A       | A     | Comfy   |20251202_172606-20251202_172909|yes|yes|yes|Modest latency increase under QoS noise|
| H4B (16GB CPU Cache) | B     | Spill   |20251202_174759-20251202_175106|yes|yes|yes|`DYN_KVBM_CPU_CACHE_GB=16`. QoS degradation increased p50 modestly and pulled p99 down vs baseline spike (QoS noise but no severe tail). CPU cache enabled; no `createXferReq` errors reported in these runs. UMA higher due to CPU cache.|
| H4B (0GB CPU Cache) | B     | Spill   |20251202_180312-20251202_180619|yes|yes|yes|GPU memory profile similar to prior run; GDS register warnings still present during init, even with CPU cache disabled. UMA remains high (~97â€¯GiB observed)|
| H1        | B     | Spill   |20251202_180619-20251202_182813 (fail); 185733/185835/185940 smokes OK; 213817 fail|yes|no|no|Smokes at lower conc/adapters clean; full run still hits request-plane timeouts. Treat as blocked until transport is fixed.|
| H3        | A     | Stress  |20251202_215631-20251202_220319|yes|yes|yes|Latency scales with context under stress; no transport issues on Stack A|
| H3        | B     | Stress  |20251202_224403-20251202_224707|yes|yes|yes|2k/4k complete and OK; 6k/8k blocked by engine max_num_tokens (requires rebuild/raise admits). Initial attention workspace resize; warmup POST (max_tokens=64) helps reduce first-request spikes|
| H5        | B     | Spill   |20251202_230454-20251202_231102|yes|yes|yes|tails grow significantly with adapter count (p95/p99 spikes at 16/64)|
| H6        | B     | Spill   |20251203_202540-20251203_202842|yes|yes|yes|LRU slightly better tail than FIFO in this run|
| H7        | B     | Stress  |20251203_204826-20251203_205640|yes|yes|yes|Tighter telemetry intervals slightly raise the p99 tail, but overall stable|
| H8        | A   | Comfy   |20251203_212228|yes|yes|yes|Revised H8 runner to honor `STACKS` to only run one stack at a time.|
| H8        | B   | Spill   |20251203_215925|yes|yes|yes|High latency at 4k ctx and that higher contexts remain blocked by the 8k token admit cap. Stack A comfy was already recorded at 2048 ctx|
| H9        | B     | Stress   |n/a|no|no|no|Blocked due to lack of OpenAI session handling plumbing|

Use this table to track the Test Plan v3.3 sweep (Stack A TRT-LLM UMA-only, Stack B Dynamo + tiered KV). Populate run IDs and notes as runs complete.

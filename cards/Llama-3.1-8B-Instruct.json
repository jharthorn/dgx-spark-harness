{
  "type": "Model",
  "namespace": "dynamo",
  "component": "tensorrt_llm",
  "endpoint": "generate",
  "instance_id": 7587890969240119941,
  "card_json": {
    "display_name": "Llama-3.1-8B-Instruct",
    "slug": "Llama-3.1-8B-Instruct",
    "hf_repo_id": "meta-llama/Llama-3.1-8B-Instruct",
    "model_info": {
      "hf_config_json": {
        "path": "/root/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/config.json",
        "checksum": "blake3:35526c33568b4823f63765ea29c1b2780659caddec1724adb057cc2495205f51"
      }
    },
    "tokenizer": {
      "hf_tokenizer_json": {
        "path": "/root/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/tokenizer.json",
        "checksum": "blake3:6c628c92d1623f93fe811c3974c81fbc415d776f33cc440d44ee6c7d9ed9e066"
      }
    },
    "prompt_formatter": {
      "hf_tokenizer_config_json": {
        "path": "/root/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/tokenizer_config.json",
        "checksum": "blake3:ea3865c7f6f322eeab4d3a61ea83102e19bcfefb5b9022acf16b8ffeaabf21c9"
      }
    },
    "gen_config": {
      "hf_generation_config_json": {
        "path": "/root/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659/generation_config.json",
        "checksum": "blake3:0523e4e0a4dd34381ea42fcf70a9e5130722c59b6c8425d5efdecac386c2790d"
      }
    },
    "context_length": 131072,
    "kv_cache_block_size": 32,
    "migration_limit": 0,
    "model_type": "Chat | Completions",
    "model_input": "Tokens",
    "runtime_config": {
      "total_kv_blocks": null,
      "max_num_seqs": 2,
      "max_num_batched_tokens": 512,
      "tool_call_parser": null,
      "reasoning_parser": null,
      "data_parallel_size": 1
    }
  }
}

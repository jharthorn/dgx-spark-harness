# KV-BM / TRT-LLM extra options for Llama 3.3 70B (Stack B Dynamo)
kv_cache_config:
  dtype: "auto"
  free_gpu_memory_fraction: 0.90
kv_connector_config:
  connector_module: kvbm.trtllm_integration.connector
  connector_scheduler_class: DynamoKVBMConnectorLeader
  connector_worker_class: DynamoKVBMConnectorWorker
# KVBM + TRT-LLM does not support CUDA graphs; disable them.
cuda_graph_config: null
disable_overlap_scheduler: true
